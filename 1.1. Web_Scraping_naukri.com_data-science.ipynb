{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c84ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82bee19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data-science-skills.xlsx\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    df = pd.DataFrame(columns=['Job_Title', 'Company', 'City', 'Salary', 'Description', 'Experience', 'Education', 'Skills'])\n",
    "    driver = webdriver.Chrome()\n",
    "    url = 'https://www.naukri.com/data-scientist-jobs'\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "\n",
    "    try:\n",
    "        # Handle popups or filters if any\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"root\"]/div[4]/div[1]/div/section[2]/div[1]/div[2]/span/span[2]/p').click()\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"root\"]/div[4]/div[1]/div/section[2]/div[1]/div[2]/span/span[2]/ul/li[2]').click()\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    pages = np.arange(1, 11) # scrap first 10 pages\n",
    "    for page in pages:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html5lib')\n",
    "        results = soup.find(class_=\"styles_job-listing-container__OCfZC\")\n",
    "\n",
    "        if results:\n",
    "            result2 = results.find_all('div', class_='srp-jobtuple-wrapper')\n",
    "\n",
    "            for job_elem in result2:\n",
    "                # Scrape Job Title\n",
    "                T = job_elem.find('a', class_=\"title \")\n",
    "                Title = T.text if T else \"Not Mentioned\"\n",
    "\n",
    "                # Scrape company name\n",
    "                company_name = \"Not Mentioned\"\n",
    "                try:\n",
    "                    C1 = job_elem.find('a', class_=\"comp-name mw-25\")\n",
    "                    Company = C1.text if C1 else \"Not Mentioned\"\n",
    "                except Exception as e:\n",
    "                    pass  # No company found in the first link\n",
    "\n",
    "                # Try to scrape company from the second link\n",
    "                try:\n",
    "                    C2 = job_elem.find('a', class_=\" comp-dtls-wrap\")\n",
    "                    if C2 and C2.text:\n",
    "                        Company = C2.text\n",
    "                except Exception as e:\n",
    "                    pass  # No company found in the second link\n",
    "                \n",
    "                # Scrape City\n",
    "                C = job_elem.find('span', class_=\"ni-job-tuple-icon ni-job-tuple-icon-srp-location loc\")\n",
    "                City = C.text if C else \"Not Mentioned\"\n",
    "\n",
    "                # Scrape Salary\n",
    "                S = job_elem.find('span', class_='ni-job-tuple-icon ni-job-tuple-icon-srp-rupee sal')\n",
    "                Salary = S.text if S else \"Not Mentioned\"\n",
    "\n",
    "                # Scrape Description\n",
    "                D = job_elem.find('span', class_=\"job-desc ni-job-tuple-icon ni-job-tuple-icon-srp-description\")\n",
    "                Description = D.text if D else \"Not Mentioned\"\n",
    "\n",
    "                # Scrape Experience\n",
    "                E = job_elem.find('span', class_=\"ni-job-tuple-icon ni-job-tuple-icon-srp-experience exp\")\n",
    "                Exp = E.text if E else \"Not Mentioned\"\n",
    "\n",
    "                # Click on the job title to open the detailed page\n",
    "                job_link = job_elem.find('a').get('href')\n",
    "                driver.execute_script(\"window.open(arguments[0])\", job_link)\n",
    "                driver.switch_to.window(driver.window_handles[-1])  # Switch to the new tab\n",
    "                time.sleep(5)  # Wait for the job details page to load\n",
    "\n",
    "                # Scrape Education and Skills from detailed job page\n",
    "                try:\n",
    "                    Education = driver.find_element(By.XPATH, '//*[@id=\"root\"]/div/main/div[1]/div[1]/section[2]/div[2]/div[3]').text\n",
    "                except:\n",
    "                    Education = \"Not Mentioned\"\n",
    "                    \n",
    "                skills_list = []\n",
    "        \n",
    "                try:\n",
    "                    skill_elements_1 = driver.find_elements(By.XPATH, '//*[@id=\"root\"]/div/main/div[1]/div[1]/section[2]/div[3]/div[2]/a')\n",
    "    \n",
    "                # Loop through each element to extract text\n",
    "                    for skill_element in skill_elements_1:\n",
    "                        skills_list.append(skill_element.text)\n",
    "\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    skill_elements_2 = driver.find_elements(By.XPATH, '//*[@id=\"root\"]/div/main/div[1]/div[1]/section[2]/div[3]/div[4]/a')\n",
    "                    for skill_element in skill_elements_2:\n",
    "                        skills_list.append(skill_element.text)\n",
    "                except Exception as e:\n",
    "                    pass  # No skills found in the second section\n",
    "\n",
    "                if not skills_list:\n",
    "                    skills_list.append(\"Not Mentioned\")  # If no skills were found in either section\n",
    "\n",
    "\n",
    "                # Close the job detail tab and switch back to the main page\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "                # Append data to DataFrame\n",
    "                df2 = pd.DataFrame([[Title, Company, City, Salary, Description, Exp, Education, skills_list]],\n",
    "                                    columns=['Job_Title', 'Company', 'City', 'Salary', 'Description', 'Experience', 'Education', 'Skills'])\n",
    "                df = pd.concat([df, df2], ignore_index=True)\n",
    "\n",
    "        # Go to the next page\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, '//*[@id=\"lastCompMark\"]/a[2]').get_attribute('href')\n",
    "            driver.get(next_button)\n",
    "            time.sleep(5)  # Give time for the page to load\n",
    "        except Exception as e:\n",
    "            print(f\"Error navigating to next page: {e}\")\n",
    "            break\n",
    "                 \n",
    "    # Save to Excel\n",
    "    output_file = \"data-science-skills.xlsx\"\n",
    "    df.to_excel(output_file, index=False, engine='openpyxl')\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a8ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
